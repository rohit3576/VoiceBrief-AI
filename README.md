```markdown
# ğŸ™ï¸ VoiceBrief AI

<div align="center">

**Transform your voice into concise summaries â€” completely free and open-source**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-2.0%2B-green)](https://flask.palletsprojects.com/)
[![Whisper](https://img.shields.io/badge/Whisper-OpenAI-yellow)](https://github.com/openai/whisper)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—-Transformers-orange)](https://huggingface.co/)
[![License](https://img.shields.io/badge/License-MIT-red.svg)](https://opensource.org/licenses/MIT)

**VoiceBrief AI** is a fully open-source, voice-driven productivity web application that records audio in the browser, transcribes speech using open-source Whisper, and generates concise summaries using transformer-based NLP models â€” all with **zero paid APIs**.

> Built for real-world usage, interviews, and deployment â€” not just demos.

</div>

---

## âœ¨ Features

| | Feature | Description |
|---|---|---|
| ğŸ¤ | **Voice Recording** | In-browser audio capture with MediaRecorder API |
| ğŸŒŠ | **Live Visualization** | Liquid glass audio effect with Web Audio API |
| ğŸ§  | **Speech-to-Text** | OpenAI's Whisper (base model) - completely local |
| ğŸ“ | **Smart Summarization** | BART transformer model for concise summaries |
| âš¡ | **Real-time Display** | Instant transcript and summary generation |
| ğŸ’¸ | **Zero Cost** | 100% free, no paid APIs, fully open-source |
| ğŸ§© | **Modular Design** | Clean architecture for easy customization |

---

## ğŸ§  How It Works

```
User Voice
â†“
Browser Recorder (MediaRecorder API)
â†“
Flask Backend
â”œâ”€â”€ Whisper â†’ Transcription
â””â”€â”€ BART â†’ Summary
â†“
Transcript + Summary shown on UI
```

---

## ğŸ› ï¸ Tech Stack

### Frontend
- HTML5
- CSS3 (Glassmorphism UI)
- JavaScript
- MediaRecorder API
- Web Audio API

### Backend
- Python
- Flask
- Open-source Whisper (Speech-to-Text)
- Hugging Face Transformers (Summarization)

### ML Models
- **Whisper (base)** â€“ Speech recognition
- **facebook/bart-large-cnn** â€“ Text summarization

---

## ğŸ“‚ Project Structure

```
VoiceBrief-AI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ whisper_transcriber.py
â”‚   â”‚   â””â”€â”€ summarizer.py
â”‚   â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/<your-username>/VoiceBrief-AI.git
cd VoiceBrief-AI
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
```

**Activate:**

**Windows**
```bash
venv\Scripts\activate
```

**macOS / Linux**
```bash
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r backend/requirements.txt
```

### 4ï¸âƒ£ Install FFmpeg

**macOS:**
```bash
brew install ffmpeg
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg
```

**Windows:**
Download from [ffmpeg.org](https://ffmpeg.org/download.html) and add to PATH

Verify installation:
```bash
ffmpeg -version
```

### 5ï¸âƒ£ Run the Application

```bash
python backend/app.py
```

**Open browser:**
```
http://127.0.0.1:5000
```

---

## ğŸ¯ Use Cases

- Meeting note summarization
- Daily voice notes
- Brain dumps & idea capture
- Interview prep recordings
- Lecture recording
- Task management

---

## ğŸ“Š Example Output

**Transcript**  
*"Today I discussed project milestones with the team. We decided to complete the API integration by Friday, and Sarah will handle the frontend components. The client meeting is scheduled for next Monday at 10 AM."*

**Summary**  
*"Team discussed project milestones, with API integration deadline set for Friday and Sarah assigned to frontend work. Client meeting scheduled for Monday at 10 AM."*

---

## ğŸ† Description

**VoiceBrief AI** - Full-stack Voice Intelligence Application
- Developed a production-grade voice processing web app using Flask and modern JavaScript
- Integrated OpenAI's Whisper model for accurate speech-to-text transcription
- Implemented BART transformer for intelligent text summarization
- Created responsive glassmorphism UI with real-time audio visualization
- Architected modular backend services for easy maintenance and scaling
- Achieved zero-cost deployment using only open-source technologies

---

## ğŸ”® Future Enhancements

- Action item extraction
- Bullet-point summaries
- Text-to-Speech playback
- Speaker diarization
- Cloud deployment (Hugging Face Spaces)
- Multi-language support
- Export to markdown/PDF
- Mobile app version
- User authentication
- Dark mode

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first.

**Steps to contribute:**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## âš ï¸ Known Issues & Troubleshooting

| Issue | Solution |
|-------|----------|
| **Slow first run** | Models need to download (~1.5GB total). Be patient! |
| **High memory usage** | Ensure 4GB+ RAM available |
| **Poor transcription** | Use clear speech, minimize background noise |
| **Microphone not working** | Check browser permissions |
| **FFmpeg not found** | Verify FFmpeg installation |

---

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgements

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Hugging Face Transformers](https://huggingface.co/)
- [Flask](https://flask.palletsprojects.com/)
- All open-source contributors

---

## ğŸ“ Contact

ğŸ“§ **Email:** rohit03576@gmail.com

ğŸ› **Report Issues:** GitHub Issues

â­ **Star this repo** if you find it useful!

---

**Made with â¤ï¸ for the open-source community**
```
